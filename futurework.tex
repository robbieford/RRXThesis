\chapter{Future Work}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%All of this should be redone...
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
For the future work for the software based demodulation algorithms, more parameter adjustment can be made to try and better fine tune the performance. For instance there are a handful of parameters in the windowed zero crossing algorithm that can be modified. As can be imagined with the Preclocking algorithm and its six stages there are even more parameters that are available for tweaking. Even with the brief time spent modifying the parameters more successfully decoded packets were acquired. Furthermore with the Preclocking algorithm, instead of only using the zero crossing frequencies inside the determined baud period a correlation of the likelihood of the two frequencies could be used as well like in Toledo’s demodulation technique. Also, continuing to investigate the source of corrupted packets and identifying corrections to improve the algorithm can be made. The current results with the Preclocking came from investigating only a handful of packets. The process is tedious and time consuming, but contains the potential for further improvements.

In addition to tweaking parameters, filtering, thresholds, etc. on the implemented algorithms there is also work that can be done on the testing, the framework, and on implementation of different algorithms.


\section{Potential Modifications to the Testing Methods}

The testing class that is currently in place was enough to meet the testing needs and see how many packets were successfully decoded by the software based algorithms. However, there is a lot more work that can be put into the testing. For instance it would be beneficial to be able just run a complete test with all of the desired input files instead of having to rerun the software for each individual file and have the testing class just print out all of the statistics at the end.

Additionally, although a little work was put into this already, it would be nice to know exactly which packets are decoded by some algorithms and not by others so that the signal can be looked at in those specific portions in order to determine what the causes of the weaknesses of the algorithm might be. It is very difficult to know what is the maximum number of packets that can be decoded from the real life test data, but as the software algorithm numbers are still under the TNCs, there are improvements to be made.

Once the packet outputs can be compared side by side it will be clearer what are the strengths and weaknesses of each algorithm. Additionally, once the packets that the software based algorithms could not demodulate are identified it would be nice to be able to look at differences between the bit stream of the correct packet and the improperly demodulated packet.

Finally, similar to how Toledo has varying parameters for his filters it would be interesting to have the program just go through and self-optimize itself. Have the tweakable parameters run through a range of values and then do analysis on the values of the internal parameters that resulted in the most decoded packets.

\section{Potential Modifications to the JavaAX25 Framework}

In addition to modifying the testing framework there is also some work that can be done on cleaning up the whole JavaAX25 package as a whole. Currently there is enough there in order to make the system work, but there are improvements that can be made in order to separate distinct algorithm logic better as well as different functional groups. For instance there is a lot of code that exists in all of the classes due to the fact that once the transitions are found calculating the number of bits and constructing the packet is always the same. If this code was put in the abstract class that all the demodulators extend from it would make the code base as a whole more robust and easier to navigate for new users to do their own analysis.

\section{Other Algorithms for Consideration}

Once the testing and framework are built into a more robust state then the focus, which is in improving the demodulation algorithms can be focused on more exclusively. From the research it can be concluded that the correlation based demodulation is as the paper title indicates a fairly “High Performance Sound Card AX.25 Modem.” However the Preclocking algorithm showed good results when using the derivative which potentially eliminates the need to run two algorithms side by side, one with an emphasis filter and one without. Using the same correlation logic on the filtered derivative instead of on the original signal is then one option to consider as a future algorithm.

Another advantage of the Preclocking algorithm was the fact that the software only has to make decisions on a single baud as opposed to all of the samples it has received thus far. If instead of using the frequencies that were extracted from the derivative data to determine the clocking, the correlation was used this may also show improvements. Basically it could be the best of both worlds since the Preclocking and correlation have already proved to work well together. 

There are many other permutations and combinations of the different algorithms that can be considered in order to try and make the algorithm as good as possible and these are only two small ideas. From the research in this paper hopefully the next implemented algorithm will take the high points and use them all together to continue to improve the software based demodulator. 
